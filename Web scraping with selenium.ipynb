{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 2 \n",
    "# Answer Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\anaconda\\lib\\site-packages (4.11.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\anaconda\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\anaconda\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium \n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : While Connecting to the automated web driver, please mention the driver path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.1. python program to scrape data for “Data Analyst” Job position in “Bangalore” location, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#Entering “Data Analyst” in “Skill, Designations, Companies” field\n",
    "\n",
    "search_job = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input')\n",
    "search_job.send_keys('Data Analyst')\n",
    "\n",
    "#entering “Bangalore” in “enter the location” field\n",
    "\n",
    "search_locn = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "search_locn.send_keys('Bangalore')\n",
    "\n",
    "#clicking the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search_button.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Data_Analyst_jobs_details():\n",
    "    #scrape first 10 jobs title\n",
    "    job_titles = []\n",
    "    title_tag = driver.find_elements(By.XPATH,\"//a[@class='title ellipsis']\")\n",
    "\n",
    "    for i in title_tag[:10]:\n",
    "        job_titles.append(i.text)\n",
    "\n",
    "    #scrape first 10 Company names\n",
    "    company_name = []\n",
    "    company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "    for i in company_tag[:10]:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "    #scrape first 10 required experience\n",
    "    experience = []\n",
    "    exp_tag = driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft expwdth']\")\n",
    "\n",
    "    for i in exp_tag[:10]:\n",
    "        experience.append(i.text)    \n",
    "\n",
    "    #scrape first 10 jobs locations   \n",
    "    Location = []\n",
    "    loc_tag = driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft locWdth']\")\n",
    "\n",
    "    for i in loc_tag[:10]:\n",
    "        Location.append(i.text)\n",
    "\n",
    "    #Creating dictionary of all titles, location, experience, company names with scaped data\n",
    "\n",
    "    dict = {'Job Title':job_titles,'Job Location': Location, 'Comapany Name':company_name, 'Expereince Required': experience,}\n",
    "\n",
    "    #Converting it into pandas dataframe\n",
    "    df = pd.DataFrame(dict)\n",
    "    \n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return df.head(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "- Top 10 job details for r “Data Analyst” Job position in “Bangalore”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Comapany Name</th>\n",
       "      <th>Expereince Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Blooprint Ecom Consulting Service</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Gurg...</td>\n",
       "      <td>Arbeit Associates</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka</td>\n",
       "      <td>Mensa Brand Technologies</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Terragig Llp</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka, Gurgaon/ Guru...</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst For Bangalore Location</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka</td>\n",
       "      <td>Teamlease Services Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Eastvantage</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Codilar</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Title  \\\n",
       "0                         Data Analyst   \n",
       "1                         Data Analyst   \n",
       "2                         Data Analyst   \n",
       "3                         Data Analyst   \n",
       "4                         Data Analyst   \n",
       "5                         Data Analyst   \n",
       "6                         Data Analyst   \n",
       "7  Data Analyst For Bangalore Location   \n",
       "8                         Data Analyst   \n",
       "9                         Data Analyst   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Hybrid - Bangalore/ Bengaluru, Karnataka, Gurg...   \n",
       "2                    Bangalore/ Bengaluru, Karnataka   \n",
       "3                                             Remote   \n",
       "4  Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...   \n",
       "5  Bangalore/ Bengaluru, Karnataka, Gurgaon/ Guru...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                    Bangalore/ Bengaluru, Karnataka   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                       Comapany Name Expereince Required  \n",
       "0  Blooprint Ecom Consulting Service             0-1 Yrs  \n",
       "1                  Arbeit Associates             3-7 Yrs  \n",
       "2           Mensa Brand Technologies             1-2 Yrs  \n",
       "3                       Terragig Llp             2-3 Yrs  \n",
       "4                              Wipro             4-8 Yrs  \n",
       "5                          Delhivery             1-3 Yrs  \n",
       "6                        Volvo Group             1-6 Yrs  \n",
       "7         Teamlease Services Limited             2-7 Yrs  \n",
       "8                        Eastvantage             4-6 Yrs  \n",
       "9                            Codilar             1-3 Yrs  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Data_Analyst_jobs_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.2.python program to scrape data for “Data Scientist” Job position in “Bangalore” location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#Entering “Data Analyst” in “Skill, Designations, Companies” field\n",
    "\n",
    "search_job = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input')\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "#entering “Bangalore” in “enter the location” field\n",
    "\n",
    "search_locn = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "search_locn.send_keys('Bangalore')\n",
    "\n",
    "#clicking the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Data_Scientist_jobs_details():\n",
    "    #scrape first 10 jobs title\n",
    "    job_titles = []\n",
    "    title_tag = driver.find_elements(By.XPATH,\"//a[@class='title ellipsis']\")\n",
    "\n",
    "    for i in title_tag[:10]:\n",
    "        job_titles.append(i.text)\n",
    "\n",
    "    #scrape first 10 Company names\n",
    "    company_name = []\n",
    "    company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "    for i in company_tag[:10]:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "    #scrape first 10 required experience\n",
    "    experience = []\n",
    "    exp_tag = driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft expwdth']\")\n",
    "\n",
    "    for i in exp_tag[:10]:\n",
    "        experience.append(i.text)    \n",
    "\n",
    "    #scrape first 10 jobs locations   \n",
    "    Location = []\n",
    "    loc_tag = driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft locWdth']\")\n",
    "\n",
    "    for i in loc_tag[:10]:\n",
    "        Location.append(i.text)\n",
    "\n",
    "    #Creating dictionary of all titles, location, experience, company names with scaped data\n",
    "\n",
    "    dict = {'Job Title':job_titles,'Job Location': Location, 'Comapany Name':company_name, 'Expereince Required': experience,}\n",
    "\n",
    "    #Converting it into pandas dataframe\n",
    "    df = pd.DataFrame(dict)\n",
    "    \n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return df.head(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Comapany Name</th>\n",
       "      <th>Expereince Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Senior Associate</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Sophos</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Sophos</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>PwC</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artificial Intelligence Senior Analyst-Intelli...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Developer</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Delh...</td>\n",
       "      <td>PwC</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manager Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa Inc</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1                  Data Scientist - Senior Associate   \n",
       "2                            Data Science Specialist   \n",
       "3                              Senior Data Scientist   \n",
       "4                              Senior Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6  Artificial Intelligence Senior Analyst-Intelli...   \n",
       "7                           Data Scientist Developer   \n",
       "8                              Senior Data Scientist   \n",
       "9                             Manager Data Scientist   \n",
       "\n",
       "                                        Job Location      Comapany Name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...          Accenture   \n",
       "1  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...                PwC   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...          Accenture   \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...             Sophos   \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...             Sophos   \n",
       "5            Bangalore/Bengaluru, Mumbai (All Areas)                PwC   \n",
       "6                                Bangalore/Bengaluru          Accenture   \n",
       "7  Hybrid - Bangalore/ Bengaluru, Karnataka, Delh...                PwC   \n",
       "8                        Bangalore/Bengaluru, Mumbai  Fractal Analytics   \n",
       "9                                Bangalore/Bengaluru           Visa Inc   \n",
       "\n",
       "  Expereince Required  \n",
       "0             6-8 Yrs  \n",
       "1             4-6 Yrs  \n",
       "2             2-4 Yrs  \n",
       "3             4-9 Yrs  \n",
       "4            5-10 Yrs  \n",
       "5             3-6 Yrs  \n",
       "6             5-8 Yrs  \n",
       "7             3-7 Yrs  \n",
       "8            5-10 Yrs  \n",
       "9            6-11 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Data_Scientist_jobs_details()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.3. Python program to use the location and salary filter, to get top 10 jobs of “Data Scientist”  at 'Delhi NCR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#URL to be web scrape\n",
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#Entering “Data Analyst” in “Skill, Designations, Companies” field\n",
    "\n",
    "search_job = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input')\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "\n",
    "#clicking the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(10) \n",
    "\n",
    "search_locn = driver.find_element(By.XPATH,\"//p/span[contains(@title,'Delhi')]\")\n",
    "search_locn.click()\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Salary range filter\n",
    "salary_button = driver.find_element(By.XPATH, '//span[contains(@title, \"3-6 Lakhs\")]')\n",
    "salary_button.click() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Data_Scientist_jobs_details():\n",
    "    #scrape first 10 jobs title\n",
    "    job_titles = []\n",
    "    title_tag = driver.find_elements(By.XPATH,\"//a[@class='title ellipsis']\")\n",
    "\n",
    "    for i in title_tag[:10]:\n",
    "        job_titles.append(i.text)\n",
    "\n",
    "    #scrape first 10 Company names\n",
    "    company_name = []\n",
    "    company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "    for i in company_tag[:10]:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "    #scrape first 10 required experience\n",
    "    experience = []\n",
    "    exp_tag = driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft expwdth']\")\n",
    "\n",
    "    for i in exp_tag[:10]:\n",
    "        experience.append(i.text)    \n",
    "\n",
    "    #scrape first 10 jobs locations   \n",
    "    Location = []\n",
    "    loc_tag = driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft locWdth']\")\n",
    "\n",
    "    for i in loc_tag[:10]:\n",
    "        Location.append(i.text)\n",
    "\n",
    "    #Creating dictionary of all titles, location, experience, company names with scaped data\n",
    "\n",
    "    dict = {'Job Title':job_titles,'Job Location': Location, 'Comapany Name':company_name, 'Expereince Required': experience,}\n",
    "\n",
    "    #Converting it into pandas dataframe\n",
    "    df = pd.DataFrame(dict)\n",
    "    \n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return df.head(10)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Comapany Name</th>\n",
       "      <th>Expereince Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python and ML Trainer</td>\n",
       "      <td>Hyderabad/Secunderabad, New Delhi, Pune, Gurga...</td>\n",
       "      <td>Thescholar</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Delhi / NCR</td>\n",
       "      <td>Grok</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Urgent Hiring -Data Scientist -(SQL, Python, P...</td>\n",
       "      <td>Delhi / NCR, Noida, Uttar Pradesh, Gurgaon/ Gu...</td>\n",
       "      <td>EXL</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>SquadRun, Inc</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                              Junior Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                              Python and ML Trainer   \n",
       "4                                     Data Scientist   \n",
       "5                              Junior Data Scientist   \n",
       "6                          Hiring For Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Urgent Hiring -Data Scientist -(SQL, Python, P...   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job Location   Comapany Name  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...        Analytos   \n",
       "1              Gurgaon/Gurugram, Bangalore/Bengaluru       Blackbuck   \n",
       "2  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...        Analytos   \n",
       "3  Hyderabad/Secunderabad, New Delhi, Pune, Gurga...      Thescholar   \n",
       "4                                              Noida  Times Internet   \n",
       "5    Gurgaon/Gurugram, United States (USA), Bulgaria          Adidas   \n",
       "6                                             Remote        Infogain   \n",
       "7                               Hybrid - Delhi / NCR            Grok   \n",
       "8  Delhi / NCR, Noida, Uttar Pradesh, Gurgaon/ Gu...             EXL   \n",
       "9                                              Noida   SquadRun, Inc   \n",
       "\n",
       "  Expereince Required  \n",
       "0             0-2 Yrs  \n",
       "1             3-7 Yrs  \n",
       "2             2-4 Yrs  \n",
       "3             3-8 Yrs  \n",
       "4             3-8 Yrs  \n",
       "5             1-6 Yrs  \n",
       "6             4-9 Yrs  \n",
       "7             3-6 Yrs  \n",
       "8             2-5 Yrs  \n",
       "9             1-4 Yrs  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Data_Scientist_jobs_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.4.Scrape data of first 100 sunglasses listings on flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "cross_button = driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "cross_button.click()\n",
    "\n",
    "#Search sunglasses product\n",
    "search_product = driver.find_element(By.XPATH,\"//input[@class='_3704LK']\")\n",
    "search_product.send_keys('sunglasses')\n",
    "\n",
    "#clicking the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "#Declaring lists for the data to be extracted\n",
    "Product_titles = []\n",
    "Product_brand = []\n",
    "Product_price= []\n",
    "\n",
    "def get_product_titles():  \n",
    "    title_tag = driver.find_elements(By.XPATH,\"//a[contains(@class,'IRpwTa')]\")\n",
    "\n",
    "    for i in title_tag:\n",
    "        Product_titles.append(i.text)\n",
    "    \n",
    "def get_product_brand():\n",
    "    brand_tag = driver.find_elements(By.XPATH,\"//div[contains(@class,'_2WkVRV')]\")\n",
    "\n",
    "    for i in brand_tag:\n",
    "        Product_brand.append(i.text)\n",
    "        \n",
    "def get_product_price():    \n",
    "    price_tag = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "\n",
    "    for i in price_tag:\n",
    "        Product_price.append(i.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list of href of next page links\n",
    "nxt_page=[]\n",
    "next_tag =driver.find_elements(By.XPATH,\"//a[contains(@class,'ge-49M')]\")\n",
    "for page in next_tag:\n",
    "    p1 = page.get_attribute('href')\n",
    "    #print(p1)\n",
    "    nxt_page.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting page 1\n",
      "Extracting page 2\n",
      "Extracting page 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UV Protection, Others Spectacle Sunglasses (Fr...</td>\n",
       "      <td>SDEEP</td>\n",
       "      <td>₹185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UV Protection Wayfarer, Sports, Spectacle , Re...</td>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>₹294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UV Protection, Polarized, Gradient, Mirrored R...</td>\n",
       "      <td>Shiv</td>\n",
       "      <td>₹275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Night Vision Aviator Sunglasses (56)</td>\n",
       "      <td>PETER JONES</td>\n",
       "      <td>₹360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Others Retro Square Sunglasses (58)</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>Singco India</td>\n",
       "      <td>₹630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product Name   Product Brand  \\\n",
       "0   UV Protection, Others Spectacle Sunglasses (Fr...           SDEEP   \n",
       "1   UV Protection Wayfarer, Sports, Spectacle , Re...         ROADWAY   \n",
       "2              UV Protection Wayfarer Sunglasses (50)            SRPM   \n",
       "3              UV Protection Wayfarer Sunglasses (50)            SRPM   \n",
       "4   UV Protection, Polarized, Gradient, Mirrored R...            Shiv   \n",
       "..                                                ...             ...   \n",
       "95               Night Vision Aviator Sunglasses (56)     PETER JONES   \n",
       "96             UV Protection Wayfarer Sunglasses (53)            SRPM   \n",
       "97                Others Retro Square Sunglasses (58)       ROYAL SON   \n",
       "98  Gradient, Toughened Glass Lens, UV Protection ...    Singco India   \n",
       "99  UV Protection Retro Square Sunglasses (Free Size)  ROZZETTA CRAFT   \n",
       "\n",
       "   Product Price  \n",
       "0           ₹185  \n",
       "1           ₹294  \n",
       "2           ₹204  \n",
       "3           ₹249  \n",
       "4           ₹275  \n",
       "..           ...  \n",
       "95          ₹360  \n",
       "96          ₹248  \n",
       "97          ₹474  \n",
       "98          ₹630  \n",
       "99          ₹471  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the required data from first three pages\n",
    "for i in range(3):\n",
    "    driver.get(nxt_page[i])\n",
    "    print('Extracting page',i+1)\n",
    "    get_product_titles()\n",
    "    get_product_brand()\n",
    "    get_product_price()\n",
    "    \n",
    "    \n",
    "    \n",
    "#Creating dictionary from the extracted data as list form\n",
    "\n",
    "dict = {'Product Name':Product_titles[:100],'Product Brand':Product_brand[:100],'Product Price':Product_price[:100]}\n",
    "dict\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART&q=iphone+11+black+64gb&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=Search&iid=179577e7-ebfd-4f68-9573-dc237ea37ee1.MOBFWQ6BXGJCEYNY.SEARCH&ppt=sp&ppn=sp&ssid=avfi6gg60g0000001667671814002&qH=c8bcf01bd7ceddcb'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "all_review = driver.find_element(By.XPATH,\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "all_review.click()\n",
    "\n",
    "star_list=[]\n",
    "review_list=[]\n",
    "summary_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_titles():  \n",
    "    review_tag = driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "\n",
    "    for i in review_tag:\n",
    "        review_list.append(i.text)\n",
    "    \n",
    "def get_review_summary():\n",
    "    summary_tag = driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "    for i in summary_tag:\n",
    "        summary_list.append(i.text)\n",
    "        \n",
    "def get_rating_stars():    \n",
    "    star_tags = driver.find_elements(By.XPATH,\"//div[contains(@class,'_3LWZlK ')]\")\n",
    "\n",
    "    for i in star_tags:\n",
    "        star_list.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxt_page=[]\n",
    "next_tag =driver.find_elements(By.XPATH,\"//a[contains(@class,'ge-49M')]\")\n",
    "for page in next_tag:\n",
    "    p1 = page.get_attribute('href')\n",
    "    #print(p1)\n",
    "    nxt_page.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting page 1\n",
      "Extracting page 2\n",
      "Extracting page 3\n",
      "Extracting page 4\n",
      "Extracting page 5\n",
      "Extracting page 6\n",
      "Extracting page 7\n",
      "Extracting page 8\n",
      "Extracting page 9\n",
      "Extracting page 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Raring Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Photos super</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s really awesome</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It is just awesome mobile for this price from ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Great product</td>\n",
       "      <td>I was using android phone earlier..I was think...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Really very nice... my dad gifted me really I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Super!</td>\n",
       "      <td>Did an upgrade from 6s plus to iphone 11.\\nAo ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Just awesome everything is perfect.\\nCamera ou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Review                                            Summary  \\\n",
       "0          Classy product  Camera is awesome\\nBest battery backup\\nA perf...   \n",
       "1                Terrific                                     Very very good   \n",
       "2   Mind-blowing purchase                                       Photos super   \n",
       "3               Wonderful                             This is amazing at all   \n",
       "4               Must buy!                                It’s really awesome   \n",
       "..                    ...                                                ...   \n",
       "95       Perfect product!  It is just awesome mobile for this price from ...   \n",
       "96          Great product  I was using android phone earlier..I was think...   \n",
       "97    Best in the market!  Really very nice... my dad gifted me really I ...   \n",
       "98                 Super!  Did an upgrade from 6s plus to iphone 11.\\nAo ...   \n",
       "99    Best in the market!  Just awesome everything is perfect.\\nCamera ou...   \n",
       "\n",
       "   Raring Stars  \n",
       "0             5  \n",
       "1             5  \n",
       "2             5  \n",
       "3             5  \n",
       "4             5  \n",
       "..          ...  \n",
       "95            5  \n",
       "96            5  \n",
       "97            5  \n",
       "98            5  \n",
       "99            5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the required data from first three pages\n",
    "for a in range(0,10):\n",
    "    driver.get(nxt_page[a])\n",
    "    print('Extracting page',a+1)\n",
    "    get_review_titles()\n",
    "    get_review_summary()\n",
    "    get_rating_stars()\n",
    "    \n",
    "    \n",
    "\n",
    "driver.close()\n",
    "#Creating dictionary from the extracted data as list form\n",
    "\n",
    "dict = {'Review':review_list,'Summary':summary_list,'Raring Stars':star_list}\n",
    "\n",
    "dict\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "try:\n",
    "    cross_button = driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "    cross_button.click()\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Search sunglasses product\n",
    "search_product = driver.find_element(By.XPATH,\"//input[@class='_3704LK']\")\n",
    "search_product.send_keys('sneakers')\n",
    "\n",
    "#clicking the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "#Declaring lists for the data to be extracted\n",
    "Product_titles = []\n",
    "Product_brand = []\n",
    "Product_price= []\n",
    "\n",
    "def get_product_titles():  \n",
    "    title_tag = driver.find_elements(By.XPATH,\"//a[contains(@class,'IRpwTa')]\")\n",
    "\n",
    "    for i in title_tag:\n",
    "        Product_titles.append(i.text)\n",
    "    \n",
    "def get_product_brand():\n",
    "    brand_tag = driver.find_elements(By.XPATH,\"//div[contains(@class,'_2WkVRV')]\")\n",
    "\n",
    "    for i in brand_tag:\n",
    "        Product_brand.append(i.text)\n",
    "        \n",
    "def get_product_price():    \n",
    "    price_tag = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "\n",
    "    for i in price_tag:\n",
    "        Product_price.append(i.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list of href of next page links\n",
    "nxt_page=[]\n",
    "next_tag =driver.find_elements(By.XPATH,\"//a[contains(@class,'ge-49M')]\")\n",
    "for page in next_tag:\n",
    "    p1 = page.get_attribute('href')\n",
    "    #print(p1)\n",
    "    nxt_page.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting page 1\n",
      "Extracting page 2\n",
      "Extracting page 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stylish Casual Sports Shoe Sneakers Sneakers F...</td>\n",
       "      <td>Layasa</td>\n",
       "      <td>₹392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casual Sneakers White Shoes For Girls And Snea...</td>\n",
       "      <td>Layasa</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>aadi</td>\n",
       "      <td>₹437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modern Trendy Sneakers boot Sneakers Sneakers ...</td>\n",
       "      <td>Magnolia</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hustle V2 Sneakers For Men</td>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹1,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SM-162 Black Walking Shoes,Training Shoes,Snea...</td>\n",
       "      <td>asian</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>₹662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>₹639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ivana Wn's Sneakers For Women</td>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SM-162 Sneakers For Men</td>\n",
       "      <td>Sparx</td>\n",
       "      <td>₹877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Product Description Product Brand  \\\n",
       "0   Stylish Casual Sports Shoe Sneakers Sneakers F...        Layasa   \n",
       "1   Casual Sneakers White Shoes For Girls And Snea...        Layasa   \n",
       "2   Synthetic Leather |Lightweight|Comfort|Summer|...          aadi   \n",
       "3   Modern Trendy Sneakers boot Sneakers Sneakers ...      Magnolia   \n",
       "4                          Hustle V2 Sneakers For Men          PUMA   \n",
       "..                                                ...           ...   \n",
       "95  SM-162 Black Walking Shoes,Training Shoes,Snea...         asian   \n",
       "96                                   Sneakers For Men    HIGHLANDER   \n",
       "97                                   Sneakers For Men    HIGHLANDER   \n",
       "98                      Ivana Wn's Sneakers For Women          PUMA   \n",
       "99                            SM-162 Sneakers For Men         Sparx   \n",
       "\n",
       "   Product Price  \n",
       "0           ₹392  \n",
       "1           ₹399  \n",
       "2           ₹437  \n",
       "3           ₹449  \n",
       "4         ₹1,499  \n",
       "..           ...  \n",
       "95          ₹599  \n",
       "96          ₹662  \n",
       "97          ₹639  \n",
       "98        ₹1,999  \n",
       "99          ₹877  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the required data from first three pages\n",
    "for i in range(3):\n",
    "    driver.get(nxt_page[i])\n",
    "    print('Extracting page',i+1)\n",
    "    get_product_titles()\n",
    "    get_product_brand()\n",
    "    get_product_price()\n",
    "    \n",
    "    \n",
    "    \n",
    "#Creating dictionary from the extracted data as list form\n",
    "\n",
    "dict = {'Product Description':Product_titles[:100],'Product Brand':Product_brand[:100],'Product Price':Product_price[:100]}\n",
    "dict\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.7.: Go to the link - https://www.myntra.com/shoes Set second Price filter and Color filter to “Black” ,scrape First 100 shoes data you get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.myntra.com/shoes'\n",
    "driver.get(url)\n",
    "\n",
    "black = driver.find_element(By.XPATH,\"(//label[@class='common-customCheckbox'])[1]\")\n",
    "black.click()\n",
    "\n",
    "price = driver.find_element(By.XPATH,\"(//label[@class='common-customCheckbox vertical-filters-label'])[9]\")\n",
    "price.click()\n",
    "\n",
    "\n",
    "Product_titles = []\n",
    "Product_brand = []\n",
    "Product_price= []\n",
    "\n",
    "def get_product_titles():  \n",
    "    title_tag = driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "\n",
    "    for i in title_tag:\n",
    "        Product_titles.append(i.text)\n",
    "    \n",
    "def get_product_brand():\n",
    "    brand_tag = driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "\n",
    "    for i in brand_tag:\n",
    "        Product_brand.append(i.text)\n",
    "        \n",
    "def get_product_price():    \n",
    "    price_tag = driver.find_elements(By.XPATH,\"//div[@class='product-price']\")\n",
    "\n",
    "    for i in price_tag:\n",
    "        Product_price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First page info\n",
    "get_product_titles()\n",
    "get_product_brand()\n",
    "get_product_price()\n",
    "\n",
    "#Clicking next button for 2nd page\n",
    "next_tag =driver.find_element(By.XPATH,\"//a[contains(text(),'2')]\")\n",
    "next_tag.click()\n",
    "\n",
    "#seconf page info\n",
    "get_product_titles()\n",
    "get_product_brand()\n",
    "get_product_price()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Men Air Force 1 '07 Sneakers</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Men Dunk High Retro Sneakers</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 9295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Men Jordan Basketball Shoes</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 10295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Men Air Force Leather Sneakers</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Jordan Legacy 312 Shoes</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Men Sporty Slip-On Sneakers</td>\n",
       "      <td>Calvin Klein Jeans</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Men Charged Bandit Trek 2</td>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Rs. 8624Rs. 11499(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Men Air Max Flyknit Sneakers</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 12295Rs. 14995(18% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Men LeBron Basketball Shoes</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 14995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Men Infinity 3 Running Shoes</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 11475Rs. 13995(18% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Product Name       Product Brand  \\\n",
       "0     Men Air Force 1 '07 Sneakers                Nike   \n",
       "1     Men Dunk High Retro Sneakers                Nike   \n",
       "2      Men Jordan Basketball Shoes                Nike   \n",
       "3   Men Air Force Leather Sneakers                Nike   \n",
       "4      Air Jordan Legacy 312 Shoes                Nike   \n",
       "..                             ...                 ...   \n",
       "95     Men Sporty Slip-On Sneakers  Calvin Klein Jeans   \n",
       "96       Men Charged Bandit Trek 2        UNDER ARMOUR   \n",
       "97    Men Air Max Flyknit Sneakers                Nike   \n",
       "98     Men LeBron Basketball Shoes                Nike   \n",
       "99    Men Infinity 3 Running Shoes                Nike   \n",
       "\n",
       "                  Product Price  \n",
       "0                      Rs. 9695  \n",
       "1                      Rs. 9295  \n",
       "2                     Rs. 10295  \n",
       "3                      Rs. 9695  \n",
       "4                     Rs. 12995  \n",
       "..                          ...  \n",
       "95                     Rs. 8999  \n",
       "96   Rs. 8624Rs. 11499(25% OFF)  \n",
       "97  Rs. 12295Rs. 14995(18% OFF)  \n",
       "98                    Rs. 14995  \n",
       "99  Rs. 11475Rs. 13995(18% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dict = {'Product Name':Product_titles[:100],'Product Brand':Product_brand[:100],'Product Price':Product_price[:100]}\n",
    "dict\n",
    "df = pd.DataFrame(dict) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.8. scrape first 10 laptops data from amazon.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.amazon.in/'\n",
    "driver.get(url)\n",
    "\n",
    "#Search sunglasses product\n",
    "search_product = driver.find_element(By.XPATH,\"//input[@id='twotabsearchtextbox']\")\n",
    "search_product.send_keys('Laptop')\n",
    "\n",
    "#clicking the search button\n",
    "search_button = driver.find_element(By.XPATH,\"//input[@id='nav-search-submit-button']\")\n",
    "search_button.click()\n",
    "\n",
    "cpu = driver.find_element(By.XPATH,\"//span[contains(text(),'Intel Core i7')]\")\n",
    "cpu.click()\n",
    "\n",
    "Product_titles = []\n",
    "Product_rating = []\n",
    "Product_price= []\n",
    "\n",
    " #Extracting the laptop name \n",
    "title_tag = driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "\n",
    "for i in title_tag:\n",
    "    Product_titles.append(i.text)\n",
    "    \n",
    " #Extracting the price\n",
    "\n",
    "price_tag = driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "\n",
    "for i in price_tag:\n",
    "    Product_price.append(i.text)\n",
    "    \n",
    " #Extracting the rating\n",
    "\n",
    "rating_tag = driver.find_elements(By.XPATH,\"//span[contains(@aria-label,'of 5 stars')]\")\n",
    "\n",
    "for i in range(15):\n",
    "    Product_rating.append(rating_tag[i].get_attribute('aria-label'))\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>68,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(16GB/512GB NVMe SSD/Windows 11 Home/Nvidia Ge...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>3.2 out of 5 stars</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>1,04,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(16GB/512GB SSD/Win 11/Office 2021/2 Years War...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>1,15,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Inspiron 5430 13th Gen</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>60,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>, Intel i7-1360P/16GB/1TB SSD/14.0\" (35.56CMs)...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>89,380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Nitro 5 AN515-58 Gaming</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12th Gen Intel Core i7-12650H NVIDIA GeForce R...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Laptop Name             Ratings  \\\n",
       "0  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...  4.0 out of 5 stars   \n",
       "1  (16GB/512GB NVMe SSD/Windows 11 Home/Nvidia Ge...  4.0 out of 5 stars   \n",
       "2  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...  3.2 out of 5 stars   \n",
       "3                                                     3.0 out of 5 stars   \n",
       "4  Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...  4.2 out of 5 stars   \n",
       "5  (16GB/512GB SSD/Win 11/Office 2021/2 Years War...  4.6 out of 5 stars   \n",
       "6                        Dell Inspiron 5430 13th Gen  3.8 out of 5 stars   \n",
       "7  , Intel i7-1360P/16GB/1TB SSD/14.0\" (35.56CMs)...  4.1 out of 5 stars   \n",
       "8                       Acer Nitro 5 AN515-58 Gaming  4.4 out of 5 stars   \n",
       "9  12th Gen Intel Core i7-12650H NVIDIA GeForce R...  4.0 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    68,990  \n",
       "1    59,990  \n",
       "2    62,990  \n",
       "3    85,990  \n",
       "4  1,04,990  \n",
       "5  1,15,990  \n",
       "6    60,990  \n",
       "7    89,380  \n",
       "8  1,29,990  \n",
       "9    79,990  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forming dataframe from extracted dictionary\n",
    "\n",
    "dict = {'Laptop Name':Product_titles[:10],'Ratings':Product_rating[:10],'Price':Product_price[:10]}\n",
    "dict\n",
    "df = pd.DataFrame(dict) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.9.Write a python program to scrape data for Top 1000 Quotes of All Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ectracting page no. 1\n",
      "Ectracting page no. 2\n",
      "Ectracting page no. 3\n",
      "Ectracting page no. 4\n",
      "Ectracting page no. 5\n",
      "Ectracting page no. 6\n",
      "Ectracting page no. 7\n",
      "Ectracting page no. 8\n",
      "Ectracting page no. 9\n",
      "Ectracting page no. 10\n",
      "Top 1000 quotes Extracted\n"
     ]
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.azquotes.com/'\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#clicking the search button\n",
    "top_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "top_button.click()\n",
    "\n",
    "#Declaring the lists\n",
    "Quote_titles = []\n",
    "Quote_Author = []\n",
    "Quote_type = []\n",
    "\n",
    "#Defining the XPATH\n",
    "title_tag = driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "Author_tag = driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "type_tag = driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "next_tag =driver.find_element(By.XPATH,\"//li[@class='next']\")\n",
    "\n",
    "\n",
    "#Extracting the information on each pages using loop\n",
    "for p in range(10):\n",
    "    print('Ectracting page no.',p+1)\n",
    "    \n",
    "    title_tag = driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "    for i in title_tag:\n",
    "        Quote_titles.append(i.text)\n",
    "    \n",
    "    Author_tag = driver.find_elements(By.XPATH,\"//div[@class='author']\")    \n",
    "    for i in Author_tag:\n",
    "        Quote_Author.append(i.text)\n",
    "    \n",
    "    type_tag = driver.find_elements(By.XPATH,\"//div[@class='tags']\")    \n",
    "    for i in type_tag:\n",
    "        Quote_type.append(i.text)\n",
    "        \n",
    "    if p<9:\n",
    "        next_tag =driver.find_element(By.XPATH,\"//li[@class='next']\")\n",
    "        next_tag.click()  \n",
    "    else:\n",
    "        print('Top 1000 quotes Extracted')\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Be more concerned with your character than you...</td>\n",
       "      <td>John Wooden</td>\n",
       "      <td>Inspirational, Success, Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weak people revenge. Strong people forgive. In...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Strong, Revenge, Intelligent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A mind is like a parachute. It doesn't work if...</td>\n",
       "      <td>Frank Zappa</td>\n",
       "      <td>Inspirational, Teacher, Religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Never be afraid to raise your voice for honest...</td>\n",
       "      <td>William Faulkner</td>\n",
       "      <td>Truth, Honesty, Lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There are three kinds of men. The one that lea...</td>\n",
       "      <td>Will Rogers</td>\n",
       "      <td>Funny, Reading, Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A strong nation, like a strong person, can aff...</td>\n",
       "      <td>Jimmy Carter</td>\n",
       "      <td>Strong, Thoughtful, Compassion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The difference between stupidity and genius is...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Love, Funny, Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>We the people are the rightful masters of both...</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Freedom, Men, Democracies Have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>With or without religion, you would have good ...</td>\n",
       "      <td>Steven Weinberg</td>\n",
       "      <td>God, Religious, Atheist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Human kindness has never weakened the stamina ...</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Respect, Kindness, Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A person who never made a mistake never tried ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>My mission in life is not merely to survive, b...</td>\n",
       "      <td>Maya Angelou</td>\n",
       "      <td>Inspirational, Life, Inspiring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Life is short, Break the Rules. Forgive quickl...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Love, Inspirational, Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This country will not be a good place for any ...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Inspiring, Country, 4th Of July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In a world filled with hate, we must still dar...</td>\n",
       "      <td>Michael Jackson</td>\n",
       "      <td>Inspirational, Dream, Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Darkness cannot drive out darkness; only light...</td>\n",
       "      <td>Martin Luther King, Jr.</td>\n",
       "      <td>Love, Inspirational, Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>To be a Christian means to forgive the inexcus...</td>\n",
       "      <td>C. S. Lewis</td>\n",
       "      <td>Forgiveness, God, Christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A man who is good enough to shed his blood for...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Men, Squares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Kindness is the language which the deaf can he...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Inspirational, Relationship, Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Most folks are as happy as they make up their ...</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Inspirational, Motivational, Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A happy marriage is the union of two good forg...</td>\n",
       "      <td>Ruth Graham</td>\n",
       "      <td>Love, Friendship, Relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I believe in Christianity as I believe that th...</td>\n",
       "      <td>C. S. Lewis</td>\n",
       "      <td>Faith, God, Christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Politics is the art of looking for trouble, fi...</td>\n",
       "      <td>Groucho Marx</td>\n",
       "      <td>Art, Freedom, Political Will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I believe in everything until it's disproved. ...</td>\n",
       "      <td>John Lennon</td>\n",
       "      <td>Inspirational, Life, Faith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the end of your life, you will never regret...</td>\n",
       "      <td>Barbara Bush</td>\n",
       "      <td>Inspirational, Life, Meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>It is best to act with confidence, no matter h...</td>\n",
       "      <td>Lillian Hellman</td>\n",
       "      <td>Confidence, Littles, Matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>People usually consider walking on water or in...</td>\n",
       "      <td>Nhat Hanh</td>\n",
       "      <td>Motivational, Buddhist, Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Freedom means the opportunity to be what we ne...</td>\n",
       "      <td>Daniel J. Boorstin</td>\n",
       "      <td>Mean, Opportunity, Nerd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>For it was not into my ear you whispered, but ...</td>\n",
       "      <td>Judy Garland</td>\n",
       "      <td>Love, Funny, Romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>I will love the light for it shows me the way,...</td>\n",
       "      <td>Og Mandino</td>\n",
       "      <td>Inspirational, Positive, Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>If you run, you are a runner. It doesn't matte...</td>\n",
       "      <td>John Bingham</td>\n",
       "      <td>Running, Years, Tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>The deepest principle in human nature is the c...</td>\n",
       "      <td>William James</td>\n",
       "      <td>Inspirational, Motivational, Relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>The world is a dangerous place to live; not be...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Peace, Integrity, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>Forgiveness says you are given another chance ...</td>\n",
       "      <td>Desmond Tutu</td>\n",
       "      <td>Inspiring, Forgiveness, New Beginnings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>About all you can do in life is be who you are...</td>\n",
       "      <td>Rita Mae Brown</td>\n",
       "      <td>Love, Life, Being Yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>To find out what one is fitted to do, and to s...</td>\n",
       "      <td>John Dewey</td>\n",
       "      <td>Happiness, Work, Opportunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>What is success? I think it is a mixture of ha...</td>\n",
       "      <td>Margaret Thatcher</td>\n",
       "      <td>Motivational, Success, Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>The past has no power over the present moment.</td>\n",
       "      <td>Eckhart Tolle</td>\n",
       "      <td>Positive, Wisdom, Philosophical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Do not let your fire go out, spark by irreplac...</td>\n",
       "      <td>Ayn Rand</td>\n",
       "      <td>Inspirational, Life, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>No person was ever honored for what he receive...</td>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Life, Leadership, Motivational Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Wherever you are, and whatever you do, be in l...</td>\n",
       "      <td>Rumi</td>\n",
       "      <td>Spiritual, Sufi, Wherever You Are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Love yourself-accept yourself-forgive yourself...</td>\n",
       "      <td>Leo Buscaglia</td>\n",
       "      <td>Love, Confidence, Forgiving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Whenever you find yourself on the side of the ...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>And those who were seen dancing were thought t...</td>\n",
       "      <td>Friedrich Nietzsche</td>\n",
       "      <td>Inspirational, Life, Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>I love things that age well - things that don'...</td>\n",
       "      <td>Giorgio Armani</td>\n",
       "      <td>Artist, Age, Example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Better be wise by the misfortunes of others th...</td>\n",
       "      <td>Aesop</td>\n",
       "      <td>Inspirational, Motivational, Wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>The person, be it gentleman or lady, who has n...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Inspirational, Funny, Stupid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Curiosity is one of the most permanent and cer...</td>\n",
       "      <td>Samuel Johnson</td>\n",
       "      <td>Education, Curiosity, Genius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Leaders must be close enough to relate to othe...</td>\n",
       "      <td>John C. Maxwell</td>\n",
       "      <td>Motivational, Inspiring, Leadership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>The opposite of love is not hate, it's indiffe...</td>\n",
       "      <td>Elie Wiesel</td>\n",
       "      <td>Love, Inspirational, Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>No matter how plain a woman may be, if truth a...</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>Beauty, Beautiful, Truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote  \\\n",
       "0    The essence of strategy is choosing what not t...   \n",
       "1    One cannot and must not try to erase the past ...   \n",
       "2    Patriotism means to stand by the country. It d...   \n",
       "3    Death is something inevitable. When a man has ...   \n",
       "4    You have to love a nation that celebrates its ...   \n",
       "5    Be more concerned with your character than you...   \n",
       "6    Weak people revenge. Strong people forgive. In...   \n",
       "7    A mind is like a parachute. It doesn't work if...   \n",
       "8    Never be afraid to raise your voice for honest...   \n",
       "9    There are three kinds of men. The one that lea...   \n",
       "10   A strong nation, like a strong person, can aff...   \n",
       "11   The difference between stupidity and genius is...   \n",
       "12   We the people are the rightful masters of both...   \n",
       "13   With or without religion, you would have good ...   \n",
       "14   Human kindness has never weakened the stamina ...   \n",
       "15   A person who never made a mistake never tried ...   \n",
       "16   My mission in life is not merely to survive, b...   \n",
       "17   Life is short, Break the Rules. Forgive quickl...   \n",
       "18   This country will not be a good place for any ...   \n",
       "19   In a world filled with hate, we must still dar...   \n",
       "20   Darkness cannot drive out darkness; only light...   \n",
       "21   To be a Christian means to forgive the inexcus...   \n",
       "22   A man who is good enough to shed his blood for...   \n",
       "23   Kindness is the language which the deaf can he...   \n",
       "24   Most folks are as happy as they make up their ...   \n",
       "25   A happy marriage is the union of two good forg...   \n",
       "26   I believe in Christianity as I believe that th...   \n",
       "27   Politics is the art of looking for trouble, fi...   \n",
       "28   I believe in everything until it's disproved. ...   \n",
       "29   At the end of your life, you will never regret...   \n",
       "..                                                 ...   \n",
       "970  It is best to act with confidence, no matter h...   \n",
       "971  People usually consider walking on water or in...   \n",
       "972  Freedom means the opportunity to be what we ne...   \n",
       "973  For it was not into my ear you whispered, but ...   \n",
       "974  I will love the light for it shows me the way,...   \n",
       "975  If you run, you are a runner. It doesn't matte...   \n",
       "976  The deepest principle in human nature is the c...   \n",
       "977  The world is a dangerous place to live; not be...   \n",
       "978  Forgiveness says you are given another chance ...   \n",
       "979  About all you can do in life is be who you are...   \n",
       "980  To find out what one is fitted to do, and to s...   \n",
       "981  What is success? I think it is a mixture of ha...   \n",
       "982     The past has no power over the present moment.   \n",
       "983  Do not let your fire go out, spark by irreplac...   \n",
       "984  No person was ever honored for what he receive...   \n",
       "985  Wherever you are, and whatever you do, be in l...   \n",
       "986  Love yourself-accept yourself-forgive yourself...   \n",
       "987  Whenever you find yourself on the side of the ...   \n",
       "988  And those who were seen dancing were thought t...   \n",
       "989  I love things that age well - things that don'...   \n",
       "990  Better be wise by the misfortunes of others th...   \n",
       "991  The person, be it gentleman or lady, who has n...   \n",
       "992  Curiosity is one of the most permanent and cer...   \n",
       "993  Leaders must be close enough to relate to othe...   \n",
       "994  The opposite of love is not hate, it's indiffe...   \n",
       "995  Regret for the things we did can be tempered b...   \n",
       "996  America... just a nation of two hundred millio...   \n",
       "997  For every disciplined effort there is a multip...   \n",
       "998  The spiritual journey is individual, highly pe...   \n",
       "999  No matter how plain a woman may be, if truth a...   \n",
       "\n",
       "                      Author                                       Type  \n",
       "0             Michael Porter   Essence, Deep Thought, Transcendentalism  \n",
       "1                 Golda Meir                  Inspiration, Past, Trying  \n",
       "2         Theodore Roosevelt                        Country, Peace, War  \n",
       "3             Nelson Mandela         Inspirational, Motivational, Death  \n",
       "4               Erma Bombeck               4th Of July, Food, Patriotic  \n",
       "5                John Wooden         Inspirational, Success, Basketball  \n",
       "6            Albert Einstein               Strong, Revenge, Intelligent  \n",
       "7                Frank Zappa          Inspirational, Teacher, Religious  \n",
       "8           William Faulkner                      Truth, Honesty, Lying  \n",
       "9                Will Rogers                   Funny, Reading, Learning  \n",
       "10              Jimmy Carter             Strong, Thoughtful, Compassion  \n",
       "11           Albert Einstein                          Love, Funny, Life  \n",
       "12           Abraham Lincoln             Freedom, Men, Democracies Have  \n",
       "13           Steven Weinberg                    God, Religious, Atheist  \n",
       "14     Franklin D. Roosevelt               Respect, Kindness, Character  \n",
       "15           Albert Einstein        Inspirational, Motivational, Change  \n",
       "16              Maya Angelou             Inspirational, Life, Inspiring  \n",
       "17                Mark Twain                  Love, Inspirational, Life  \n",
       "18        Theodore Roosevelt            Inspiring, Country, 4th Of July  \n",
       "19           Michael Jackson                 Inspirational, Dream, Hate  \n",
       "20   Martin Luther King, Jr.                  Love, Inspirational, Life  \n",
       "21               C. S. Lewis                Forgiveness, God, Christian  \n",
       "22        Theodore Roosevelt                      Country, Men, Squares  \n",
       "23                Mark Twain      Inspirational, Relationship, Positive  \n",
       "24           Abraham Lincoln      Inspirational, Motivational, Positive  \n",
       "25               Ruth Graham             Love, Friendship, Relationship  \n",
       "26               C. S. Lewis                      Faith, God, Christian  \n",
       "27              Groucho Marx               Art, Freedom, Political Will  \n",
       "28               John Lennon                 Inspirational, Life, Faith  \n",
       "29              Barbara Bush            Inspirational, Life, Meaningful  \n",
       "..                       ...                                        ...  \n",
       "970          Lillian Hellman                Confidence, Littles, Matter  \n",
       "971                Nhat Hanh           Motivational, Buddhist, Children  \n",
       "972       Daniel J. Boorstin                    Mean, Opportunity, Nerd  \n",
       "973             Judy Garland                      Love, Funny, Romantic  \n",
       "974               Og Mandino             Inspirational, Positive, Stars  \n",
       "975             John Bingham                      Running, Years, Tests  \n",
       "976            William James  Inspirational, Motivational, Relationship  \n",
       "977          Albert Einstein                Peace, Integrity, Patriotic  \n",
       "978             Desmond Tutu     Inspiring, Forgiveness, New Beginnings  \n",
       "979           Rita Mae Brown                 Love, Life, Being Yourself  \n",
       "980               John Dewey               Happiness, Work, Opportunity  \n",
       "981        Margaret Thatcher                Motivational, Success, Work  \n",
       "982            Eckhart Tolle            Positive, Wisdom, Philosophical  \n",
       "983                 Ayn Rand          Inspirational, Life, Motivational  \n",
       "984          Calvin Coolidge      Life, Leadership, Motivational Sports  \n",
       "985                     Rumi          Spiritual, Sufi, Wherever You Are  \n",
       "986            Leo Buscaglia                Love, Confidence, Forgiving  \n",
       "987               Mark Twain        Inspirational, Motivational, Change  \n",
       "988      Friedrich Nietzsche                 Inspirational, Life, Music  \n",
       "989           Giorgio Armani                       Artist, Age, Example  \n",
       "990                    Aesop          Inspirational, Motivational, Wise  \n",
       "991              Jane Austen               Inspirational, Funny, Stupid  \n",
       "992           Samuel Johnson               Education, Curiosity, Genius  \n",
       "993          John C. Maxwell        Motivational, Inspiring, Leadership  \n",
       "994              Elie Wiesel                  Love, Inspirational, Life  \n",
       "995         Sydney J. Harris          Love, Inspirational, Motivational  \n",
       "996       Hunter S. Thompson                     Gun, Two, Qualms About  \n",
       "997                 Jim Rohn      Inspirational, Greatness, Best Effort  \n",
       "998                 Ram Dass                     Spiritual, Truth, Yoga  \n",
       "999        Eleanor Roosevelt                   Beauty, Beautiful, Truth  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forming dataframe from extracted dictionary\n",
    "dict = {'Quote':Quote_titles,'Author':Quote_Author,'Type':Quote_type}\n",
    "dict\n",
    "df = pd.DataFrame(dict) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Write s python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,Term of office, Remarks) from https://www.jagranjosh.com/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Vinit\\Downloads\\chromedriver.exe')\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.jagranjosh.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#clicking the gk button\n",
    "gk_button = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[6]/div/div[1]/header/div[3]/ul/li[9]/a\")\n",
    "gk_button.click()\n",
    "\n",
    "#Clicking the prime minister link\n",
    "primeminister_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "primeminister_button.click()\n",
    "\n",
    "#DEclaring the lists\n",
    "Names = []\n",
    "Born_dead = []\n",
    "Office_tenure = []\n",
    "Remarks = []\n",
    "\n",
    "#DEfining the XPATH\n",
    "name_tag = driver.find_elements(By.XPATH,\"//td[contains(@style,'width: 150px')]\")\n",
    "born_dead_tag = driver.find_elements(By.XPATH,\"//td[contains(@style,'width: 105px')]\")\n",
    "Office_tag = driver.find_elements(By.XPATH,\"//td[contains(@style,'width: 256px')]\")\n",
    "remark_tag = driver.find_elements(By.XPATH,\"//td[contains(@style,'width: 145px')]\")\n",
    "\n",
    "#Extracting data\n",
    "for i in name_tag:\n",
    "        Names.append(i.text)\n",
    "for i in born_dead_tag:\n",
    "        Born_dead.append(i.text)\n",
    "for i in Office_tag:\n",
    "        Office_tenure.append(i.text)\n",
    "for i in remark_tag:\n",
    "        Remarks.append(i.text)\n",
    "        \n",
    "driver.close()\n",
    "        \n",
    "#Creating dictionary and then, dataframe from dictionary\n",
    "\n",
    "dict = {'Name':Names,'Born-Dead':Born_dead,'Office Tenure':Office_tenure,'Remarks':Remarks}\n",
    "df = pd.DataFrame(dict) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q11: Write s python program to display list of 50 Most expensive cars in the world (i.e. Company name, Model name and Price) from https://www.motor1.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTE</td>\n",
       "      <td>Drako</td>\n",
       "      <td>Price: $1.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tomaso</td>\n",
       "      <td>De</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LaFerrari</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Huayra</td>\n",
       "      <td>Pagani</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elva</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21C</td>\n",
       "      <td>Czinger</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Monza</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Murray</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gemera</td>\n",
       "      <td>Koenigsegg</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TSR-S</td>\n",
       "      <td>Zenvo</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Venom</td>\n",
       "      <td>Hennessey</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bacalar</td>\n",
       "      <td>Bentley</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Suiza</td>\n",
       "      <td>Hispano</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mulliner</td>\n",
       "      <td>Bentley</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vayanne</td>\n",
       "      <td>Deus</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tuatara</td>\n",
       "      <td>SSC</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Evija</td>\n",
       "      <td>Lotus</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Martin</td>\n",
       "      <td>Aston</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>D12</td>\n",
       "      <td>Delage</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Speedtail</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nevera</td>\n",
       "      <td>Rimac</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Utopia</td>\n",
       "      <td>Pagani</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Battista</td>\n",
       "      <td>Pininfarina</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FXX</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Murray</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Countach</td>\n",
       "      <td>Lamborghini</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Project</td>\n",
       "      <td>Mercedes-AMG</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Martin</td>\n",
       "      <td>Aston</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Venom</td>\n",
       "      <td>Hennessey</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Jesko</td>\n",
       "      <td>Koenigsegg</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Martin</td>\n",
       "      <td>Aston</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Motors</td>\n",
       "      <td>W</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Solus</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Huayra</td>\n",
       "      <td>Pagani</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Chiron</td>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sian</td>\n",
       "      <td>Lamborghini</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CC850</td>\n",
       "      <td>Koenigsegg</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Chiron</td>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Veneno</td>\n",
       "      <td>Lamborghini</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bolide</td>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Mistral</td>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Huayra</td>\n",
       "      <td>Pagani</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Divo</td>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>SP</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Codalunga</td>\n",
       "      <td>Pagani</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Exelero</td>\n",
       "      <td>Mercedes-Maybach</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Centodieci</td>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sweptail</td>\n",
       "      <td>Rolls-Royce</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>La</td>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Boat</td>\n",
       "      <td>Rolls-Royce</td>\n",
       "      <td>Price: $28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model             Brand                        Price\n",
       "0          GTE             Drako          Price: $1.2 Million\n",
       "1       Tomaso                De          Price: $1.3 Million\n",
       "2    LaFerrari           Ferrari          Price: $1.4 Million\n",
       "3       Huayra            Pagani          Price: $1.4 Million\n",
       "4         Elva           McLaren          Price: $1.7 Million\n",
       "5          21C           Czinger          Price: $1.7 Million\n",
       "6        Monza           Ferrari          Price: $1.7 Million\n",
       "7       Murray            Gordon          Price: $1.7 Million\n",
       "8       Gemera        Koenigsegg          Price: $1.7 Million\n",
       "9        TSR-S             Zenvo          Price: $1.7 Million\n",
       "10       Venom         Hennessey          Price: $1.8 Million\n",
       "11     Bacalar           Bentley          Price: $1.9 Million\n",
       "12       Suiza           Hispano          Price: $1.9 Million\n",
       "13    Mulliner           Bentley          Price: $2.0 Million\n",
       "14     Vayanne              Deus          Price: $2.0 Million\n",
       "15     Tuatara               SSC         Price: $2.0 Million*\n",
       "16       Evija             Lotus          Price: $2.1 Million\n",
       "17      Martin             Aston          Price: $2.3 Million\n",
       "18         D12            Delage          Price: $2.3 Million\n",
       "19   Speedtail           McLaren          Price: $2.3 Million\n",
       "20      Nevera             Rimac          Price: $2.4 Million\n",
       "21      Utopia            Pagani          Price: $2.5 Million\n",
       "22    Battista       Pininfarina          Price: $2.5 Million\n",
       "23         FXX           Ferrari          Price: $2.6 Million\n",
       "24      Murray            Gordon          Price: $2.6 Million\n",
       "25    Countach       Lamborghini          Price: $2.6 Million\n",
       "26     Project      Mercedes-AMG          Price: $2.7 Million\n",
       "27      Martin             Aston          Price: $3.0 Million\n",
       "28       Venom         Hennessey                 $3.0 Million\n",
       "29       Jesko        Koenigsegg          Price: $3.0 Million\n",
       "30      Martin             Aston          Price: $3.2 Million\n",
       "31      Motors                 W          Price: $3.4 Million\n",
       "32       Solus           McLaren                 $3.5 Million\n",
       "33      Huayra            Pagani          Price: $3.5 Million\n",
       "34      Chiron           Bugatti          Price: $3.6 Million\n",
       "35        Sian       Lamborghini          Price: $3.6 million\n",
       "36       CC850        Koenigsegg          Price: $3.7 Million\n",
       "37      Chiron           Bugatti          Price: $3.9 Million\n",
       "38      Veneno       Lamborghini          Price: $4.5 Million\n",
       "39      Bolide           Bugatti          Price: $4.7 Million\n",
       "40     Mistral           Bugatti          Price: $5.0 Million\n",
       "41      Huayra            Pagani          Price: $5.4 Million\n",
       "42        Divo           Bugatti          Price: $5.8 Million\n",
       "43  Automotive                SP          Price: $6.4 Million\n",
       "44   Codalunga            Pagani          Price: $7.4 Million\n",
       "45     Exelero  Mercedes-Maybach          Price: $8.0 Million\n",
       "46  Centodieci           Bugatti          Price: $9.0 Million\n",
       "47    Sweptail       Rolls-Royce         Price: $12.8 Million\n",
       "48          La           Bugatti         Price: $13.4 Million\n",
       "49        Boat       Rolls-Royce  Price: $28.0 Million (est.)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome(r'C:\\Users\\Vinit\\Downloads\\chromedriver.exe')\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.motor1.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#clicking the search button\n",
    "menu_button = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div[1]/div\")\n",
    "menu_button.click()\n",
    "\n",
    "#Heading towards list\n",
    "list_button = driver.find_element(By.XPATH,\"//body/div[3]/div[1]/div[3]/ul[1]/li[4]/a[1]\")\n",
    "l1=list_button.get_attribute('href')\n",
    "driver.get(l1)\n",
    "\n",
    "#Redirecting towrds top 50 cars\n",
    "topic_tag = driver.find_element(By.XPATH,'/html/body/div[2]/div[9]/div[1]/div[1]/div/div/div[1]/div/div[1]/h3/a')\n",
    "p1=topic_tag.get_attribute('href')\n",
    "driver.get(p1)\n",
    "\n",
    "#Initiating lists\n",
    "Titles = []\n",
    "company_name = []\n",
    "price = []\n",
    "car =[]\n",
    "final_price = []\n",
    "\n",
    "#Extracting car model and company together\n",
    "title_tag = driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in title_tag:\n",
    "    Titles.append(i.text.split())\n",
    "    \n",
    "#Seperating company name\n",
    "for i in Titles:\n",
    "    company_name.append(i[0])\n",
    "\n",
    "#Seperating car model\n",
    "for i in Titles:\n",
    "    car.append(i[1])\n",
    "\n",
    "#Extracting prices for cars    \n",
    "price_tag = driver.find_elements(By.XPATH,\"//strong[contains(text(),'$')]\")\n",
    "for i in price_tag:\n",
    "    price.append(i.text)\n",
    "\n",
    "driver.close()\n",
    "#creating a dictionary of data collected in form of lists\n",
    "dict = {'Model':car[:50],'Brand':company_name[:50],'Price':price[:50]}\n",
    "\n",
    "#Creating dataframe from dictionary\n",
    "df = pd.DataFrame(dict) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
