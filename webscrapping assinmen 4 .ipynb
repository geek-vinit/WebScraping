{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.11.2-py3-none-any.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\anaconda\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\anaconda\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "     -------------------------------------- 400.2/400.2 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.1.2 h11-0.14.0 outcome-1.2.0 selenium-4.11.2 trio-0.22.2 trio-websocket-0.10.3 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import re\n",
    "import pandas as pd\n",
    "!pip install selenium \n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title of Exception</th>\n",
       "      <th>Discription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title of Exception  \\\n",
       "0      ElementNotVisibleException   \n",
       "1   ElementNotSelectableException   \n",
       "2          NoSuchElementException   \n",
       "3            NoSuchFrameException   \n",
       "4         NoAlertPresentException   \n",
       "\n",
       "                                         Discription  \n",
       "0   This type of Selenium exception occurs when a...  \n",
       "1   This Selenium exception occurs when an elemen...  \n",
       "2   This Exception occurs if an element could not...  \n",
       "3   This Exception occurs if the frame target to ...  \n",
       "4   This Exception occurs when you switch to no p...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.guru99.com/'\n",
    "driver.get(url)\n",
    "driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "time.sleep(50)\n",
    "\n",
    "#Search for selenium exception\n",
    "search_selenium = driver.find_element(By.XPATH,\"//input[@class='gsc-input']\")\n",
    "search_selenium.send_keys('selenium exception handling')\n",
    "\n",
    "\n",
    "#clicking the search button\n",
    "search_button = driver.find_element(By.XPATH,\"//button[@class='gsc-search-button gsc-search-button-v2']\")\n",
    "search_button.click()\n",
    "time.sleep(5)\n",
    "    \n",
    "search_result=driver.find_element(By.XPATH,\"(//div[@class='gs-title']/a)[1]\")\n",
    "resultURL = search_result.get_attribute('href')\n",
    "driver.get(resultURL)\n",
    "time.sleep(10)\n",
    "    \n",
    "title= []\n",
    "discription = []\n",
    "\n",
    "titleTags =driver.find_elements(By.XPATH,\"//article[@id='post-1953']/div/div/p/strong\")\n",
    "discrpTags =driver.find_elements(By.XPATH,\"//article[@id='post-1953']/div/div/p\")\n",
    "\n",
    "for i in range(41):\n",
    "    title.append(titleTags[i].text.split('.')[1].split(':')[0])\n",
    "    discription.append(discrpTags[i].text.split(':')[1])   \n",
    "\n",
    "    \n",
    "dictionary= {'Title of Exception':title,'Discription':discription}\n",
    "driver.close()\n",
    "df = pd.DataFrame.from_dict(dictionary)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seven</td>\n",
       "      <td>Jung Kook Featuring Latto</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Try That In A Small Town</td>\n",
       "      <td>Jason Aldean</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Song                     Artist Last Week Rank  \\\n",
       "Rank                                                                       \n",
       "1                        Seven  Jung Kook Featuring Latto              -   \n",
       "2     Try That In A Small Town               Jason Aldean              -   \n",
       "3                   Last Night              Morgan Wallen              1   \n",
       "4                     Fast Car                 Luke Combs              2   \n",
       "5                    Calm Down        Rema & Selena Gomez              4   \n",
       "\n",
       "     Peak Rank Weeks on Chart  \n",
       "Rank                           \n",
       "1            1              1  \n",
       "2            2              1  \n",
       "3            1             25  \n",
       "4            2             17  \n",
       "5            3             46  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.billboard.com/'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "    \n",
    "chartmenu = driver.find_element(By.XPATH,\"//div[@id='main-wrapper']/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")\n",
    "URL=chartmenu.get_attribute('href')\n",
    "driver.get(URL)\n",
    "time.sleep(5)\n",
    "\n",
    "viewchart = driver.find_element(By.XPATH,\"//div[@id='main-wrapper']/main/div[2]/div[1]/div[1]/div/div/div[3]/a\")\n",
    "finalURL = viewchart.get_attribute('href')\n",
    "driver.get(finalURL)\n",
    "time.sleep(5)\n",
    "\n",
    "rowtag = driver.find_elements(By.XPATH,\"//div[@class='o-chart-results-list-row-container']\")\n",
    "RANKS = []\n",
    "SONGS = []\n",
    "ARTISTS = []\n",
    "LASTWEEKS = []\n",
    "PEAKS = []\n",
    "WEEKSONCHART = []\n",
    "for i in range (len(rowtag)):\n",
    "    rank = driver.find_elements(By.XPATH,\"//div/div[2]/div/ul/li[1]/span[@class='c-label  a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet']\")\n",
    "    RANKS.append(rank[i].text)\n",
    "    song = driver.find_elements(By.XPATH,\"//li/h3[@id='title-of-a-story']\")\n",
    "    SONGS.append(song[i].text)\n",
    "    artist = driver.find_elements(By.XPATH,\"//div[2]/div/ul/li[4]/ul/li[1]/span\")\n",
    "    ARTISTS.append(artist[i].text)\n",
    "    lastweek = driver.find_elements(By.XPATH,\"//div/div[2]/div/ul/li[4]/ul/li[4]/span\")\n",
    "    LASTWEEKS.append(lastweek[i].text)\n",
    "    peak = driver.find_elements(By.XPATH,\"//div[2]/div/ul/li[4]/ul/li[5]/span\")\n",
    "    PEAKS.append(peak[i].text)\n",
    "    weeksOnchart = driver.find_elements(By.XPATH,\"//div/div[2]/div/ul/li[4]/ul/li[6]/span\")\n",
    "    WEEKSONCHART.append(weeksOnchart[i].text)\n",
    "    \n",
    "dictionary= {'Rank':RANKS,'Song':SONGS,'Artist':ARTISTS,'Last Week Rank':LASTWEEKS,'Peak Rank':PEAKS,'Weeks on Chart':WEEKSONCHART}\n",
    "driver.close()\n",
    "df = pd.DataFrame.from_dict(dictionary)\n",
    "df = df.set_index('Rank')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Scrape the details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Comapny</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Manager</td>\n",
       "      <td>PwC</td>\n",
       "      <td></td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Banga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Application Lead</td>\n",
       "      <td>-</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>data cleansing, Data analysis, Team management...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Analyst, Customer Analytics(Data Scienc...</td>\n",
       "      <td>-</td>\n",
       "      <td>Western Union Financial Services, Inc</td>\n",
       "      <td>Data Science, Data management, Data analytics,...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Market Mix Modelling</td>\n",
       "      <td>PwC</td>\n",
       "      <td>Analyst, Health insurance, Digital media, cust...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Market Mix Modelling</td>\n",
       "      <td>PwC</td>\n",
       "      <td>data cleansing, Data analysis, Business analyt...</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Banga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Manager</td>\n",
       "      <td>Analytics &amp; Data Science</td>\n",
       "      <td>BMC Software</td>\n",
       "      <td>data cleansing, Data analysis, Business analyt...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Applied Intelligence Analyst / Consultant</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>SAS, Data management, Project management, Anal...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Market Mix Modelling Manager</td>\n",
       "      <td>PwC</td>\n",
       "      <td>Applied Intelligence, SQL, R, Spark, Python, D...</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Banga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Analyst/ Data Scientist</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>data cleansing, Data analysis, Business analyt...</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Senior Data Scientist ( Credit Risk Modelling )</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>customer analytics, data science, regression, ...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senior Analyst</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>Data analysis, EDC, risk modeling, Machine lea...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Head</td>\n",
       "      <td>Business Analytics &amp; Data Science</td>\n",
       "      <td>Denave</td>\n",
       "      <td>Analyst, data science, Process documentation, ...</td>\n",
       "      <td>Noida, Uttar Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Head</td>\n",
       "      <td>Business Analytics &amp; Data Science</td>\n",
       "      <td>Denave</td>\n",
       "      <td>Business Analytics, Predictive Modeling, data ...</td>\n",
       "      <td>Noida, Uttar Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Engineer/data Science Consultant</td>\n",
       "      <td>-</td>\n",
       "      <td>Career Infosystem</td>\n",
       "      <td>Business Analytics, Predictive Modeling, data ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Science Analytics Sr Analyst</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Science, Business Intelligence, ETL Tools...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Science Tech Lead</td>\n",
       "      <td>-</td>\n",
       "      <td>Legatohealthcom</td>\n",
       "      <td>Data Science, Publishing, Artificial Intellige...</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>-</td>\n",
       "      <td>Uber</td>\n",
       "      <td>SAN, data science, Machine learning, Wellness,...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Senior Analyst</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Jardine Lloyd Thompson</td>\n",
       "      <td>Computer science, Root cause analysis, Data an...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Analyst</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Marsh McLennan Companies</td>\n",
       "      <td>Business improvement, Data analysis, Data mode...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>-</td>\n",
       "      <td>Conneqt Digital</td>\n",
       "      <td>data science, Senior Analyst, Senior, Data ana...</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "0                                        Data Science   \n",
       "1                       Data Science Application Lead   \n",
       "2   Senior Analyst, Customer Analytics(Data Scienc...   \n",
       "3                                        Data Science   \n",
       "4                                       Data Science    \n",
       "5                                            Manager    \n",
       "6          Applied Intelligence Analyst / Consultant    \n",
       "7                                       Data Science    \n",
       "8                     Senior Analyst/ Data Scientist    \n",
       "9                                       Data Science    \n",
       "10                                    Senior Analyst    \n",
       "11                                              Head    \n",
       "12                                              Head    \n",
       "13              Data Engineer/data Science Consultant   \n",
       "14                 Data Science Analytics Sr Analyst    \n",
       "15                             Data Science Tech Lead   \n",
       "16                               Data Science Manager   \n",
       "17                                    Senior Analyst    \n",
       "18                                    Senior Analyst    \n",
       "19                              Data Science Engineer   \n",
       "\n",
       "                                         Designation  \\\n",
       "0                                            Manager   \n",
       "1                                                  -   \n",
       "2                                                  -   \n",
       "3                              Market Mix Modelling    \n",
       "4                              Market Mix Modelling    \n",
       "5                           Analytics & Data Science   \n",
       "6                                         Marketing    \n",
       "7                       Market Mix Modelling Manager   \n",
       "8                                       Data Science   \n",
       "9    Senior Data Scientist ( Credit Risk Modelling )   \n",
       "10                                      Data Science   \n",
       "11                 Business Analytics & Data Science   \n",
       "12                 Business Analytics & Data Science   \n",
       "13                                                 -   \n",
       "14                                      Data Science   \n",
       "15                                                 -   \n",
       "16                                                 -   \n",
       "17                                      Data Science   \n",
       "18                                      Data Science   \n",
       "19                                                 -   \n",
       "\n",
       "                                  Comapny  \\\n",
       "0                                     PwC   \n",
       "1                               Accenture   \n",
       "2   Western Union Financial Services, Inc   \n",
       "3                                     PwC   \n",
       "4                                     PwC   \n",
       "5                            BMC Software   \n",
       "6                               Accenture   \n",
       "7                                     PwC   \n",
       "8                         Tiger Analytics   \n",
       "9                                   Paytm   \n",
       "10                        Tiger Analytics   \n",
       "11                                 Denave   \n",
       "12                                 Denave   \n",
       "13                      Career Infosystem   \n",
       "14                              Accenture   \n",
       "15                        Legatohealthcom   \n",
       "16                                   Uber   \n",
       "17                 Jardine Lloyd Thompson   \n",
       "18               Marsh McLennan Companies   \n",
       "19                        Conneqt Digital   \n",
       "\n",
       "                                               Skills  \\\n",
       "0                                                       \n",
       "1   data cleansing, Data analysis, Team management...   \n",
       "2   Data Science, Data management, Data analytics,...   \n",
       "3   Analyst, Health insurance, Digital media, cust...   \n",
       "4   data cleansing, Data analysis, Business analyt...   \n",
       "5   data cleansing, Data analysis, Business analyt...   \n",
       "6   SAS, Data management, Project management, Anal...   \n",
       "7   Applied Intelligence, SQL, R, Spark, Python, D...   \n",
       "8   data cleansing, Data analysis, Business analyt...   \n",
       "9   customer analytics, data science, regression, ...   \n",
       "10  Data analysis, EDC, risk modeling, Machine lea...   \n",
       "11  Analyst, data science, Process documentation, ...   \n",
       "12  Business Analytics, Predictive Modeling, data ...   \n",
       "13  Business Analytics, Predictive Modeling, data ...   \n",
       "14  Data Science, Business Intelligence, ETL Tools...   \n",
       "15  Data Science, Publishing, Artificial Intellige...   \n",
       "16  SAN, data science, Machine learning, Wellness,...   \n",
       "17  Computer science, Root cause analysis, Data an...   \n",
       "18  Business improvement, Data analysis, Data mode...   \n",
       "19  data science, Senior Analyst, Senior, Data ana...   \n",
       "\n",
       "                                             Location  \n",
       "0   Kolkata, Mumbai, Hyderabad/Secunderabad, Banga...  \n",
       "1                                             Chennai  \n",
       "2                                                Pune  \n",
       "3         Hyderabad/Secunderabad, Bangalore/Bengaluru  \n",
       "4   Kolkata, Mumbai, Hyderabad/Secunderabad, Banga...  \n",
       "5                                                Pune  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7   Kolkata, Mumbai, Hyderabad/Secunderabad, Banga...  \n",
       "8   Hyderabad/Secunderabad, Chennai, Bangalore/Ben...  \n",
       "9                                               Noida  \n",
       "10                                            Chennai  \n",
       "11                               Noida, Uttar Pradesh  \n",
       "12                               Noida, Uttar Pradesh  \n",
       "13                                Bangalore/Bengaluru  \n",
       "14                                             Mumbai  \n",
       "15                             Hyderabad/Secunderabad  \n",
       "16                                Bangalore/Bengaluru  \n",
       "17                                             Mumbai  \n",
       "18                                             Mumbai  \n",
       "19                       Hybrid - Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "#Search Data science jobs\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input\")\n",
    "search.send_keys('Data Science')\n",
    "\n",
    "\n",
    "#clicking the search button\n",
    "search_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[6]\")\n",
    "search_button.click()\n",
    "time.sleep(10)\n",
    "\n",
    "results = driver.find_elements(By.XPATH,\"//*[@id='root']/div[4]/div/div/section[2]/div[2]/article\")\n",
    "\n",
    "def listToString(tra):\n",
    "   \n",
    "    # initialize an empty string\n",
    "    str1 = \", \"\n",
    "   \n",
    "    # return string \n",
    "    return (str1.join(tra))\n",
    "\n",
    "Name = []\n",
    "Designation =[]\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []\n",
    "\n",
    "\n",
    "for i in range(len(results)):\n",
    "    \n",
    "    Title = driver.find_elements(By.XPATH,\"//article/div[1]/div[1]/a\")\n",
    "    try:\n",
    "        Designation.append(Title[i].text.split('-')[1])\n",
    "        Name.append(Title[i].text.split('-')[0])\n",
    "        \n",
    "    except:\n",
    "        Name.append(Title[i].text)\n",
    "        Designation.append('-')\n",
    "\n",
    "    org = driver.find_elements(By.XPATH,\"//article/div[1]/div[1]/div/a[1]\")\n",
    "    Company.append(org[i].text)\n",
    "\n",
    "    skillpath = (\"//article\"+str([i])+\"/ul/li\")\n",
    "    Skill = driver.find_elements(By.XPATH,skillpath)\n",
    "    tra = []\n",
    "    for s in range(len(Skill)):\n",
    "        tra.append(Skill[s].text)\n",
    "    Skills.append(listToString(tra))\n",
    "    \n",
    "    \n",
    "    location = driver.find_elements(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[2]/div[2]/article/div[1]/ul/li[3]/span\")\n",
    "    Location.append(location[i].text)\n",
    "    \n",
    "    \n",
    "dictionary= {'Job Title':Name,'Designation':Designation,'Comapny':Company,'Skills':Skills,'Location':Location}\n",
    "driver.close()\n",
    "df = pd.DataFrame.from_dict(dictionary)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. Scrape the details most watched tv series of all time from imdb.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (114.0.5735.90) detected in PATH at C:\\Users\\Neon Tech Ent\\Data Science\\Final projects\\Web Scraping\\chromedriver.exe might not be compatible with the detected chrome version (115.0.5790.110); currently, chromedriver 115.0.5790.102 is recommended for chrome 115.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Run Time in Min.</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>57 min</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,187,318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>51 min</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,262,175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>44 min</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,038,502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>60 min</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.5</td>\n",
       "      <td>305,227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>43 min</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orange Is the New Black</td>\n",
       "      <td>(2013–2019)</td>\n",
       "      <td>59 min</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>8.1</td>\n",
       "      <td>312,008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Riverdale</td>\n",
       "      <td>(2017–2023)</td>\n",
       "      <td>45 min</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>6.5</td>\n",
       "      <td>150,255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grey's Anatomy</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>41 min</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>7.6</td>\n",
       "      <td>325,783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Flash</td>\n",
       "      <td>(2014–2023)</td>\n",
       "      <td>43 min</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>7.5</td>\n",
       "      <td>361,464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arrow</td>\n",
       "      <td>(2012–2020)</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>7.5</td>\n",
       "      <td>439,791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Movie Name    Year Span Run Time in Min.  \\\n",
       "0          Game of Thrones  (2011–2019)           57 min   \n",
       "1          Stranger Things  (2016–2024)           51 min   \n",
       "2         The Walking Dead  (2010–2022)           44 min   \n",
       "3           13 Reasons Why  (2017–2020)           60 min   \n",
       "4                  The 100  (2014–2020)           43 min   \n",
       "5  Orange Is the New Black  (2013–2019)           59 min   \n",
       "6                Riverdale  (2017–2023)           45 min   \n",
       "7           Grey's Anatomy     (2005– )           41 min   \n",
       "8                The Flash  (2014–2023)           43 min   \n",
       "9                    Arrow  (2012–2020)           42 min   \n",
       "\n",
       "                      Genre Rating      Votes  \n",
       "0  Action, Adventure, Drama    9.2  2,187,318  \n",
       "1    Drama, Fantasy, Horror    8.7  1,262,175  \n",
       "2   Drama, Horror, Thriller    8.1  1,038,502  \n",
       "3  Drama, Mystery, Thriller    7.5    305,227  \n",
       "4    Drama, Mystery, Sci-Fi    7.6    264,323  \n",
       "5      Comedy, Crime, Drama    8.1    312,008  \n",
       "6     Crime, Drama, Mystery    6.5    150,255  \n",
       "7            Drama, Romance    7.6    325,783  \n",
       "8  Action, Adventure, Drama    7.5    361,464  \n",
       "9  Action, Adventure, Crime    7.5    439,791  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calling the automated chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "#URL to be web scrape\n",
    "\n",
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "\n",
    "results = driver.find_elements(By.XPATH,\"//div[@id='main']/div/div[3]/div[3]/div\")\n",
    "\n",
    "Name =[]\n",
    "Year = []\n",
    "RunTime = []\n",
    "Genere = []\n",
    "Rating = []\n",
    "Vote = []\n",
    "\n",
    "for i in range(len(results)):  \n",
    "    nametag = driver.find_elements(By.XPATH,\"//div[@id='main']/div/div[3]/div[3]/div/div[2]/h3/a\")\n",
    "    Name.append(nametag[i].text)\n",
    "    yeartag = driver.find_elements(By.XPATH,\"//div[@id='main']/div/div[3]/div[3]/div/div[2]/h3/span[2]\")\n",
    "    Year.append(yeartag[i].text)\n",
    "    timetag = driver.find_elements(By.XPATH,\"//div[@id='main']/div/div[3]/div[3]/div/div[2]/p[1]/span[3]\")\n",
    "    RunTime.append(timetag[i].text)\n",
    "    generetag = driver.find_elements(By.XPATH,\"//div[@id='main']/div/div[3]/div[3]/div/div[2]/p[1]/span[5]\")\n",
    "    Genere.append(generetag[i].text)\n",
    "    ratingtag = driver.find_elements(By.XPATH,\"//div[@id='main']/div/div[3]/div[3]/div/div[2]/div[1]/div[1]/span[2]\")\n",
    "    Rating.append(ratingtag[i].text)\n",
    "    votetag = driver.find_elements(By.XPATH,\"//div[@id='main']/div/div[3]/div[3]/div/div[2]/p[4]/span[2]\")\n",
    "    Vote.append(votetag[i].text)\n",
    "\n",
    "    \n",
    "dictionary= {'Movie Name':Name,'Year Span':Year,'Run Time in Min.':RunTime,'Genre': Genere,'Rating':Rating,'Votes':Vote}\n",
    "driver.close()\n",
    "df = pd.DataFrame.from_dict(dictionary)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
